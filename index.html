<!DOCTYPE HTML>
<html lang="en">
<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <meta name="google-site-verification" content="_RzqNiCkRu4_4tNavp7_SyhCbSOItLeeOTXKRoPujX4" />
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-155128387-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-155128387-1');
  </script>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <title>Tianrui Liu</title>
  <meta name="author" content="Tianrui Liu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon.png">
</head>

<body>
  <div class="container">
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Tianrui Liu</name>
              </p>
              <p style="text-align:justify">I am now a Lecturer at the Department of Computer Science, National University of Defense Technology (NUDT). 
                Before, I was a Postdoc Resesarcher in the <a href="https://biomedia.doc.ic.ac.uk/">BioMedIA</a> Group in Imperial College London, advised by <a href="http://wp.doc.ic.ac.uk/dr/">Professor Daniel Rueckert</a> and <a href="https://www.imperial.ac.uk/people/b.kainz">Dr. Bernhard Kainz</a>.

              </p>
              <p style="text-align:justify">
                I'm interested in computer vision, deep learning, object detection and pattern recognition, image and video processing and medical image analysis.
              </p>

              <p style="text-align:justify">
          In my spare time, I like playing piano, reading and playing badminton.
              </p>

              <p style="text-align:center">
                <a href="mailto:trliu@nudt.edu.cn">Email</a> &nbsp/&nbsp
                <a href="data/Tianrui_CV_2021.pdf">CV</a> &nbsp/&nbsp
               
                <a href="https://scholar.google.com/citations?user=SC53gxAAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://uk.linkedin.com/in/tianrui-liu-7b126b67"> LinkedIn </a>
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <a href="images/tianrui_web.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/tianrui_web.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Education</heading>
              <p>
                <ul>
                  <li style="line-height:200%">
                  <div><strong>Ph.D</strong> in Computer Vision and Image Processing, Imperial College London</div>
                  <div style="float: right; text-align: right; margin: -28px; padding-right: 19px"><em>Nov. 2015 - Nov. 2019</em></div>
                </li>
                <li style="line-height:200%">
                  <div><strong>M.Phil.</strong> in Image and Video Processing, University of Hong Kong</div>
                  <div style="float: right; text-align: right; margin: -28px; padding-right: 19px"><em>Sep. 2013 - Nov. 2015</em></div>
                </li>
                <li style="line-height:200%">
                  <div><strong>B.Eng.</strong> (First Class Honours) in EIE, Hong Kong Polytechnic University</div>
                  <div style="float: right; text-align: right; margin: -28px; padding-right: 19px"><em>Sep. 2011 - Jun. 2013</em></div>
                </li>
                <li style="line-height:200%">
                  <div><strong>B.Eng.</strong> in Microelectronics, San Yat-Sen University</div> 
                  <div style="float: right; text-align: right; margin: -28px; padding-right: 19px"><em>Sep. 2009 - Jun. 2011</em></div>
                </li> 
              </ul>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Working Experience / Activities</heading>
              <p>
                <ul>
                <li style="line-height:200%">
                  <div>Resesarch Associate @ Imperial College London.</div>
                  <div style="float: right; text-align: right; margin: -28px; padding-right: 19px"><em>Aug. 2019 - Aug. 2021</em></div>
                </li>
                <li style="line-height:200%">
                  <div>Research Intern @ Tencent AI Lab (Shenzhen, China), advised by <a href="https://whluo.github.io/">Dr. Wenhan Luo</a> </div>
                  <div style="float: right; text-align: right; margin: -28px; padding-right: 19px"><em>Mar. 2020 - Now</em></div>
                </li>

                <li style="line-height:200%">
                  <div>Visiting Research Scholar @ Hong Kong Polytechnic University, advised by <a href="https://www.eie.polyu.edu.hk/~enkmlam/">Prof. Kenneth K. M. Lam</a></div>
                  <div style="float: right; text-align: right; margin: -28px; padding-right: 19px"><em>Aug. 2018</em></div>
                </li>

                <li style="line-height:200%">
                  <div>Research Intern @ RISA Sicherheitsanalysen GmbH (Berlin, Germany)</div>
                  <div style="float: right; text-align: right; margin: -28px; padding-right: 19px"><em>June. 2018 - Sep. 2018</em></div>
                </li>

                <li style="line-height:200%">
                  <div>Visiting Research Scholar @ Hong Kong Polytechnic University, advised by <a href="http://eie.polyu.edu.hk/~wcsiu/">Prof. Wan-Chi Siu</a></div>
                  <div style="float: right; text-align: right; margin: -28px; padding-right: 19px"><em>Jun. 2016 - Aug. 2016</em></div>
                </li>
                  
              </ul>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Selected Publications</heading> 
            </td>
          </tr>
        </tbody></table>
        <p>
        For a complete list, please check my <a href="https://scholar.google.com/citations?user=SC53gxAAAAAJ&hl=en">Google Scholar</a>.
        </p>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


          <!-- # TIP paper: Coupled-Network for Robust Pedestrian Detection with Gated Multi-Layer Feature Extraction and Deformable Occlusion Handling -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/Ped_couple.png' height="100%" width="100%">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/1912.08324.pdf">
                <papertitle>Coupled-Network for Robust Pedestrian Detection with Gated Multi-Layer Feature Extraction and Deformable Occlusion Handling</papertitle>
              </a>
              <br>
              <strong>Tianrui Liu</strong>,
              Wenhan Luo, 
              Lin Ma, 
              Junjie Huang, 
              Tania Stathaki,
              Tianhong Dai,
              <br>
              <em>IEEE Transactions on Image Processing</em>, 2020
              <br>
              <a href="https://arxiv.org/pdf/1912.08324.pdf">pdf</a> /
              <a href="BibTeX/TIP_Coupled_2019.bib">bibtex</a>
              <br>
              <p></p>
              <p style="text-align:justify">In this paper, we propose a gated multi-layer convolutional feature extraction method which can adaptively generate discriminative features for candidate pedestrian regions.</p>
            </td>
          </tr>

          
          <!-- # paper: MICCAI: Ultrasound Video Summarization using Deep Reinforcement Learning -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/MICCAI2020_icon.png' height="100%" width="100%">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2005.09531.pdf">
                <papertitle>Ultrasound Video Summarization using Deep Reinforcement Learning</papertitle>
              </a>
              <br>
              <strong>Tianrui Liu</strong>,
              Qingjie Meng, 
              Athanasios Vlontzos, 
              Jeremy Tan, 
              Daniel Rueckert, 
              Bernhard Kainz
              <br>
              <em>International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI)</em>, 2020
              <br>
              <a href="https://arxiv.org/pdf/2005.09531.pdf">pdf</a> /
              <a href="BibTeX/MICCAI_2020.bib">bibtex</a>
              <br>
              <p></p>
              <p style="text-align:justify">We propose an ultrasound video summarization method to summarize the long examination videos. The proposed method can remove parts that are not relevant for diagnostics and meanwhile guarantees the preservation of decisive diagnostic information.</p>
            </td>
          </tr>


          <!-- # paper: Diagnosis- Exploring a new paradigm for the fetal anomaly ultrasound scan -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/US_diagnosis.png' height="100%" width="100%">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/2005.09531.pdf">
                <papertitle>Exploring a new paradigm for the fetal anomaly ultrasound scan: Artificial intelligence in real time</papertitle>
              </a>
              <br>
              Jacqueline Matthew,
              Emily Skelton,
              Thomas G. Day,
              Veronika A. Zimmer,
              Alberto Gomez,
              Gavin Wheeler,
              Nicolas Toussaint,
              <strong>Tianrui Liu</strong>,
              Samuel Budd,
              Karen Lloyd,
              Robert Wright,
              Shujie Deng,
              Nooshin Ghavami,
              Matthew Sinclair,
              Qingjie Meng,
              Bernhard Kainz,
              Julia A. Schnabel,
              Daniel Rueckert,
              Reza Razavi,
              John Simpson,
              Jo Hajnal
              <br>
              <em>Prenatal Diagnosis</em>, 2021
              <br>
              <a href="https://obgyn.onlinelibrary.wiley.com/doi/epdf/10.1002/pd.6059">pdf</a> /
              <a href="BibTeX/US_diagnosis.bib">bibtex</a>
              <br>
              <p></p>
              <p style="text-align:justify">We piloted the end-to-end automation of the mid-trimester screening ultrasound scan using AI enabled tools. Survey responses suggest that the AI toolshelped sonographers to concentrate on image interpretation by removing disruptivetasks.</p>
            </td>
          </tr>

          <!-- # paper: Gated Multi-layer Convolutional Feature Extraction Network for Robust Pedestrian Detection -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/gated_detection.png' height="100%" width="100%">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/pdf/1910.11761.pdf">
                <papertitle>Gated Multi-layer Convolutional Feature Extraction Network for Robust Pedestrian Detection</papertitle>
              </a>
              <br>
              <strong>Tianrui Liu</strong>,
              Jun-Jie Huang,
              Tianhong Dai,
              Guangyu Ren,
              Tania Stathaki
              <br>
              <em>International Conference on Acoustics, Speech, and Signal Processing (ICASSP)</em>, 2020
              <br>
              <a href="https://arxiv.org/pdf/1910.11761.pdf">pdf</a> /
              <a href="BibTeX/ICASSP_gate.bib">bibtex</a>
              <br>
              <p></p>
              <p style="text-align:justify"> In this paper, we propose a gated multi-layer convolutional feature extraction method which can adaptively generate discriminative features for candidate pedestrian regions.</p>
            </td>
          </tr>

          <!-- # BMVC paper: SAM-RCNN: Scale-Aware Multi-Resolution Multi-Channel Pedestrian Detection -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/Ped_SAM.png' height="100%" width="100%">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.semanticscholar.org/paper/SAM-RCNN%3A-Scale-Aware-Multi-Resolution-Pedestrian-Liu-Elmikaty/955aa3e7317e236e41f05ec2853b64236c252af0">
                <papertitle>SAM-RCNN: Scale-Aware Multi-Resolution Multi-Channel Pedestrian Detection</papertitle>
              </a>
              <br>
              <strong>Tianrui Liu</strong>,
              Mohamed ElMikaty, 
              Tania Stathaki
              <br>
              <em>British Machine Vision Conference (BMVC)</em>, 2019
              <br>
              <a href="http://bmvc2018.org/contents/papers/0793.pdf">pdf</a> /
              <a href="BibTeX/BMVC_2018.bib">bibtex</a>
              <br>
              <p></p>
              <p style="text-align:justify">We exploits different combination of multi-resolution CNN features for pedestrian candidates of different scales.</p>
            </td>
          </tr>


          <!-- # : Faster R-CNN for robust pedestrian detection using semantic segmentation network -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/Frontiers_2018.png' height="100%" width="100%">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.frontiersin.org/articles/10.3389/fnbot.2018.00064/full">
                <papertitle>Faster R-CNN for robust pedestrian detection using semantic segmentation network</papertitle>
              </a>
              <br>
              <strong>Tianrui Liu</strong>,
              Tania Stathaki
              <br>
              <em>Frontiers in Neurorobotics</em>, 2018
              <br>
              <a href="https://www.frontiersin.org/articles/10.3389/fnbot.2018.00064/full">pdf</a> /
              <a href="BibTeX/frontiers_2018.bib">bibtex</a>
              <br>
              <p></p>
              <p style="text-align:justify">Our method extends the Faster R-CNN detection framework by adding a branch of network for semantic image segmentation.</p>
            </td>
          </tr>

          <!-- # paper: SRHRF+: Self-Example Enhanced Single Image Super-Resolution Using Hierarchical Random Forests -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/CVPRW.png' height="100%" width="100%">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://ieeexplore.ieee.org/document/8014878">
                <papertitle>SRHRF+: Self-Example Enhanced Single Image Super-Resolution Using Hierarchical Random Forests</papertitle>
              </a>
              <br>
              Jun-jie Huang,
              <strong>Tianrui Liu</strong>,
              Pier Luigi Dragotti,
              Tania Stathaki,
              <br>
              <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshop</em>, 2017
              <br>
              <a href="https://openaccess.thecvf.com/content_cvpr_2017_workshops/w12/papers/Huang_SRHRF_Self-Example_Enhanced_CVPR_2017_paper.pdf">pdf</a> /
              <a href="BibTeX/CVPRW_2017.bib">bibtex</a>
              <br>
              <p></p>
              <p style="text-align:justify">A novel hierarchical random forests based super-resolution (SRHRF) method is proposed to learn statistical priors from external training images.</p>
            </td>
          </tr>

         <!-- # paper: Hierarchical Semantic Image Labelling method via Random Forests -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/TENCON_RF.png' height="100%" width="100%">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://www.semanticscholar.org/paper/A-hierarchical-semantic-image-labeling-method-via-Liu-Chan/3913dce14585851541543dabbb60419d9f152096">
                <papertitle>Hierarchical Semantic Image Labelling method via Random Forests</papertitle>
              </a>
              <br>
              <strong>Tianrui Liu</strong>,
              Shing Chow Chan
              <br>
              <em>IEEE Region 10 Conference TENCON <strong>(Young Scientist Award)</strong></em>, 2015.
              <br>
              <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7372791&tag=1">pdf</a> /
              <a href="BibTeX/TENCON_2015.bib">bibtex</a>
              <br>
              <p></p>
              <p style="text-align:justify">We propose an effective image labeling method with a hierarchical framework consists of two layers of random forests (RF). In the first layer, RF is performed on superpixel basis. In the second layer, structured RF is applied to make use of the topological distribution of the object classes.</p>
            </td>
          </tr>


         <!-- # paper: Fast Image Interpolation via Random Forests -->
          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <img src='images/TIP_2015.png' height="100%" width="100%">
              </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://www.eie.polyu.edu.hk/~wcsiu/softmodule/10/fast_image_interpolation.htm">
                <papertitle>Fast Image Interpolation via Random Forests</papertitle>
              </a>
              <br>
              Jun-jie Huang,
              Wan-Chi Siu,
              <strong>Tianrui Liu</strong>
              <br>
              <em>IEEE Transactions on Image Processing</em>, 2015.
              <br>
              <a href="https://ieeexplore.ieee.org/document/7117405/">pdf</a> /
              <a href="BibTeX/TIP_2015.bib">bibtex</a>
              <br>
              <p></p>
              <p style="text-align:justify">We propose a two-stage framework for fast image interpolation via random forests. The underlying idea of this proposed work is to apply random forests to classify the natural image patch space into numerous subspaces and learn a linear regression model for each subspace to map the low-resolution image patch to high-resolution image patch.</p>
            </td>
          </tr>

        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Selected Awards</heading>

              <p>
                <ul>
                <li style="line-height:200%">
                  <div>Chinese Government Award for Outstanding (Non-Government Sponsored) Students Abroad ($6,000)</div>
                  <div style="float: right; text-align: right; margin: -28px; padding-right: 19px"><em>2020 </em></div>
                </li>

                <li style="line-height:200%">
                  <div>Imperial College Department Scholarship (£130,000), Imperial College London</div>
                  <div style="float: right; text-align: right; margin: -28px; padding-right: 19px"><em>2016 - 2019 </em></div>
                </li>

                <li style="line-height:200%">
                  <div>Young Scientist Award, IEEE Region 10 Conference TENCON </div>
                  <div style="float: right; text-align: right; margin: -28px; padding-right: 19px"><em>2015 </em></div>
                </li>

                <li style="line-height:200%">
                  <div>Dean's List of Outstanding Students, HKPolyU</div>
                  <div style="float: right; text-align: right; margin: -28px; padding-right: 19px"><em>2012 & 2013</em></div>
                </li>

                <li style="line-height:200%">
                  <div>Outstanding Performance Scholarship (HK$ 80,000), HKSAR Government</div>
                  <div style="float: right; text-align: right; margin: -28px; padding-right: 19px"><em>2012</em></div>
                </li>
                <li style="line-height:200%">
                  <div>PolyU EIE (Non-local Student) Scholarship (HK$ 100,000), HKPolyU</div> 
                  <div style="float: right; text-align: right; margin: -28px; padding-right: 19px"><em>2011</em></div>
                </li> 
              </ul>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading> Professional Activities</heading>

              <p>
                <ul>

                <p style="text-align:left">
                  Journal Reviewer: 
                </p>
                <li style="line-height:150%">
                  <div>IEEE Transactions on Image Processing (TIP) </div>
                </li>

                <li style="line-height:150%">
                  <div>IEEE Transactions on Neural Networks and Learning Systems (TNNLS) </div>
                </li>

                <li style="line-height:150%">
                  <div>IEEE Transactions on Medical Imaging (TMI)</div>
                </li>

                <li style="line-height:150%">
                  <div>Transactions on Geoscience and Remote Sensing (TGRS)</div>
                </li>
                
                <li style="line-height:150%">
                  <div>IEEE Transactions on Multimedia (TMM)</div>
                </li>

                <li style="line-height:150%">
                  <div>IEEE Internet of Things Journal (IoT)</div>
                </li>
                <li style="line-height:150%">
                  <div>Future Generation Computer Systems  </div>
                </li>

                <li style="line-height:150%">
                  <div>Pattern Recognation, etc.  </div>
                </li>

              </ul>
              </p>
            </td>
          </tr>
        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Talks</heading>

              <p>
                <ul>
                  <li style="line-height:160%">
                  <div>Deep learning in Pedestrian Detection and Video Analysis<br>
                  @Huazhong University of Science and Technology, WuHan, China</div>
                  <div style="float: right; text-align: right; margin: -48px; padding-right: 19px"><em>Dec. 2020</em></div>
                </li>

                <li style="line-height:160%">
                  <div>Deep Learning for Pedestrian Detection and Medical Video Summarization<br>
                  @Nanjing University of Aeronautics and Astronautics, NanJing, China</div>
                  <div style="float: right; text-align: right; margin: -48px; padding-right: 19px"><em>Sep. 2020</em></div>
                </li>
                  <li style="line-height:160%">
                  <div>What Can Help Pedestrian Detection?<br>
                  @National University of Defense Technology, ChangSha, China</div>
                  <div style="float: right; text-align: right; margin: -48px; padding-right: 19px"><em>Dec. 2019</em></div>
                </li>

                <li style="line-height:160%">
                  <div>Deep Learning for Pedestrian Detection under Complex Environment<br>
                  @NorthEast University，Department of Computer Science, ShenYang, China</div>
                  <div style="float: right; text-align: right; margin: -48px; padding-right: 19px"><em>Dec. 2019</em></div>
                </li>

                <li style="line-height:160%">
                  <div>Enhanced Pedestrian Detection using Deep Learning based Semantic Segmentation and Scale-Aware Scheme <br>
                  @National Technical University of Athens, Athens, Greece</div> 
                  <div style="float: right; text-align: right; margin: -48px; padding-right: 19px"><em>Sept. 2018</em></div>
                  
                </li> 
                <li style="line-height:160%">
                  <div>Low Resolution Face Detection for Video Surveillance Technologies<br>
                  @Artificial Intelligence and Mulitmedia Lab, HK PolyU, HK</div> 
                  <div style="float: right; text-align: right; margin: -48px; padding-right: 19px"><em>Sept. 2018</em></div>
              </ul>
              </p>
            </td>
          </tr>
        </tbody></table>



       
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                <br>
                <hr>
                The original template of this page can be found from <a href="https://github.com/jonbarron/website">here</a>.
              </p>
            </td>
          </tr>
        </tbody></table>

      </td>
    </tr>
  </table>
</div>
</body>
</html>
